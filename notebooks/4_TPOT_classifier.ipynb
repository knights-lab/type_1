{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib: 3.3.4\n",
      "seaborn   : 0.11.1\n",
      "numpy     : 1.20.1\n",
      "pandas    : 1.1.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "np.random.seed(930525)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "warnings.simplefilter('once')\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhillmann/.conda/envs/tpot-cuml/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import PredefinedSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhillmann/.conda/envs/tpot-cuml/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/home/bhillmann/.conda/envs/tpot-cuml/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3156: DtypeWarning: Columns (73,86,98,99,103,106,107,111,112,204,217,229,230,234,237,238,242,243) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_type_1_features = pd.read_csv(\"../data/strains.dataset.tree.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_type_1_features['dataset_cat'] = pd.Series([_.split(\"_\")[0] for _ in df_type_1_features['dataset']], dtype='category')\n",
    "CV = PredefinedSplit(df_type_1_features['dataset_cat'].cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15921\n",
      "18806\n",
      "21665\n",
      "21036\n",
      "13506\n",
      "16495\n",
      "16662\n"
     ]
    }
   ],
   "source": [
    "for name, group in df_type_1_features.groupby('dataset'):\n",
    "    print(len(group['assembly_accession'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0009831494628941664"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_type_1_features['truth'].sum() / df_type_1_features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['assembly_accession',\n",
       " 'tree_closest_assembly_accession',\n",
       " 'tree_dist',\n",
       " 'tree_top_dist',\n",
       " 'hits',\n",
       " 'percent_coverage',\n",
       " 'mean_coverage',\n",
       " 'sd_coverage',\n",
       " 'percent_padded_coverage',\n",
       " 'mean_padded_coverage',\n",
       " 'sd_padded_coverage',\n",
       " 'percent_binned_coverage',\n",
       " 'mean_binned_coverage',\n",
       " 'sd_binned_coverage',\n",
       " 'expected_percent_coverage',\n",
       " 'shannon_entropy',\n",
       " 'percent_max_uncovered_region',\n",
       " 'largest_pileup',\n",
       " 'largest_padded_pileup',\n",
       " 'largest_binned_pileup',\n",
       " 'gc_content',\n",
       " 'total_genome_length',\n",
       " 'ungapped_genome_length',\n",
       " 'num_n_groups',\n",
       " 'consecutive_ns',\n",
       " 'gf_accession',\n",
       " 'gf_ambiguous_bases',\n",
       " 'gf_checkm_completeness',\n",
       " 'gf_checkm_contamination',\n",
       " 'gf_checkm_marker_count',\n",
       " 'gf_checkm_marker_lineage',\n",
       " 'gf_checkm_marker_set_count',\n",
       " 'gf_checkm_strain_heterogeneity',\n",
       " 'gf_coding_bases',\n",
       " 'gf_coding_density',\n",
       " 'gf_contig_count',\n",
       " 'gf_gc_count',\n",
       " 'gf_gc_percentage',\n",
       " 'gf_genome_size',\n",
       " 'gf_gtdb_genome_representative',\n",
       " 'gf_gtdb_representative',\n",
       " 'gf_gtdb_taxonomy',\n",
       " 'gf_gtdb_type_designation',\n",
       " 'gf_gtdb_type_designation_sources',\n",
       " 'gf_gtdb_type_species_of_genus',\n",
       " 'gf_l50_contigs',\n",
       " 'gf_l50_scaffolds',\n",
       " 'gf_longest_contig',\n",
       " 'gf_longest_scaffold',\n",
       " 'gf_lsu_23s_contig_len',\n",
       " 'gf_lsu_23s_count',\n",
       " 'gf_lsu_23s_length',\n",
       " 'gf_lsu_23s_query_id',\n",
       " 'gf_lsu_5s_contig_len',\n",
       " 'gf_lsu_5s_count',\n",
       " 'gf_lsu_5s_length',\n",
       " 'gf_lsu_5s_query_id',\n",
       " 'gf_lsu_silva_23s_blast_align_len',\n",
       " 'gf_lsu_silva_23s_blast_bitscore',\n",
       " 'gf_lsu_silva_23s_blast_evalue',\n",
       " 'gf_lsu_silva_23s_blast_perc_identity',\n",
       " 'gf_lsu_silva_23s_blast_subject_id',\n",
       " 'gf_lsu_silva_23s_taxonomy',\n",
       " 'gf_mean_contig_length',\n",
       " 'gf_mean_scaffold_length',\n",
       " 'gf_mimag_high_quality',\n",
       " 'gf_mimag_low_quality',\n",
       " 'gf_mimag_medium_quality',\n",
       " 'gf_n50_contigs',\n",
       " 'gf_n50_scaffolds',\n",
       " 'gf_ncbi_assembly_level',\n",
       " 'gf_ncbi_assembly_name',\n",
       " 'gf_ncbi_assembly_type',\n",
       " 'gf_ncbi_bioproject',\n",
       " 'gf_ncbi_biosample',\n",
       " 'gf_ncbi_contig_count',\n",
       " 'gf_ncbi_contig_n50',\n",
       " 'gf_ncbi_country',\n",
       " 'gf_ncbi_date',\n",
       " 'gf_ncbi_genbank_assembly_accession',\n",
       " 'gf_ncbi_genome_category',\n",
       " 'gf_ncbi_genome_representation',\n",
       " 'gf_ncbi_isolate',\n",
       " 'gf_ncbi_isolation_source',\n",
       " 'gf_ncbi_lat_lon',\n",
       " 'gf_ncbi_molecule_count',\n",
       " 'gf_ncbi_ncrna_count',\n",
       " 'gf_ncbi_organism_name',\n",
       " 'gf_ncbi_protein_count',\n",
       " 'gf_ncbi_refseq_category',\n",
       " 'gf_ncbi_rrna_count',\n",
       " 'gf_ncbi_scaffold_count',\n",
       " 'gf_ncbi_scaffold_l50',\n",
       " 'gf_ncbi_scaffold_n50',\n",
       " 'gf_ncbi_scaffold_n75',\n",
       " 'gf_ncbi_scaffold_n90',\n",
       " 'gf_ncbi_seq_rel_date',\n",
       " 'gf_ncbi_spanned_gaps',\n",
       " 'gf_ncbi_species_taxid',\n",
       " 'gf_ncbi_ssu_count',\n",
       " 'gf_ncbi_strain_identifiers',\n",
       " 'gf_ncbi_submitter',\n",
       " 'gf_ncbi_taxid',\n",
       " 'gf_ncbi_taxonomy',\n",
       " 'gf_ncbi_taxonomy_unfiltered',\n",
       " 'gf_ncbi_total_gap_length',\n",
       " 'gf_ncbi_total_length',\n",
       " 'gf_ncbi_translation_table',\n",
       " 'gf_ncbi_trna_count',\n",
       " 'gf_ncbi_type_material_designation',\n",
       " 'gf_ncbi_ungapped_length',\n",
       " 'gf_ncbi_unspanned_gaps',\n",
       " 'gf_ncbi_wgs_master',\n",
       " 'gf_protein_count',\n",
       " 'gf_scaffold_count',\n",
       " 'gf_ssu_contig_len',\n",
       " 'gf_ssu_count',\n",
       " 'gf_ssu_gg_blast_align_len',\n",
       " 'gf_ssu_gg_blast_bitscore',\n",
       " 'gf_ssu_gg_blast_evalue',\n",
       " 'gf_ssu_gg_blast_perc_identity',\n",
       " 'gf_ssu_gg_blast_subject_id',\n",
       " 'gf_ssu_gg_taxonomy',\n",
       " 'gf_ssu_length',\n",
       " 'gf_ssu_query_id',\n",
       " 'gf_ssu_silva_blast_align_len',\n",
       " 'gf_ssu_silva_blast_bitscore',\n",
       " 'gf_ssu_silva_blast_evalue',\n",
       " 'gf_ssu_silva_blast_perc_identity',\n",
       " 'gf_ssu_silva_blast_subject_id',\n",
       " 'gf_ssu_silva_taxonomy',\n",
       " 'gf_total_gap_length',\n",
       " 'gf_trna_aa_count',\n",
       " 'gf_trna_count',\n",
       " 'gf_trna_selenocysteine_count',\n",
       " 'tree_hits',\n",
       " 'tree_percent_coverage',\n",
       " 'tree_mean_coverage',\n",
       " 'tree_sd_coverage',\n",
       " 'tree_percent_padded_coverage',\n",
       " 'tree_mean_padded_coverage',\n",
       " 'tree_sd_padded_coverage',\n",
       " 'tree_percent_binned_coverage',\n",
       " 'tree_mean_binned_coverage',\n",
       " 'tree_sd_binned_coverage',\n",
       " 'tree_expected_percent_coverage',\n",
       " 'tree_shannon_entropy',\n",
       " 'tree_percent_max_uncovered_region',\n",
       " 'tree_largest_pileup',\n",
       " 'tree_largest_padded_pileup',\n",
       " 'tree_largest_binned_pileup',\n",
       " 'tree_gc_content',\n",
       " 'tree_total_genome_length',\n",
       " 'tree_ungapped_genome_length',\n",
       " 'tree_num_n_groups',\n",
       " 'tree_consecutive_ns',\n",
       " 'tree_gf_accession',\n",
       " 'tree_gf_ambiguous_bases',\n",
       " 'tree_gf_checkm_completeness',\n",
       " 'tree_gf_checkm_contamination',\n",
       " 'tree_gf_checkm_marker_count',\n",
       " 'tree_gf_checkm_marker_lineage',\n",
       " 'tree_gf_checkm_marker_set_count',\n",
       " 'tree_gf_checkm_strain_heterogeneity',\n",
       " 'tree_gf_coding_bases',\n",
       " 'tree_gf_coding_density',\n",
       " 'tree_gf_contig_count',\n",
       " 'tree_gf_gc_count',\n",
       " 'tree_gf_gc_percentage',\n",
       " 'tree_gf_genome_size',\n",
       " 'tree_gf_gtdb_genome_representative',\n",
       " 'tree_gf_gtdb_representative',\n",
       " 'tree_gf_gtdb_taxonomy',\n",
       " 'tree_gf_gtdb_type_designation',\n",
       " 'tree_gf_gtdb_type_designation_sources',\n",
       " 'tree_gf_gtdb_type_species_of_genus',\n",
       " 'tree_gf_l50_contigs',\n",
       " 'tree_gf_l50_scaffolds',\n",
       " 'tree_gf_longest_contig',\n",
       " 'tree_gf_longest_scaffold',\n",
       " 'tree_gf_lsu_23s_contig_len',\n",
       " 'tree_gf_lsu_23s_count',\n",
       " 'tree_gf_lsu_23s_length',\n",
       " 'tree_gf_lsu_23s_query_id',\n",
       " 'tree_gf_lsu_5s_contig_len',\n",
       " 'tree_gf_lsu_5s_count',\n",
       " 'tree_gf_lsu_5s_length',\n",
       " 'tree_gf_lsu_5s_query_id',\n",
       " 'tree_gf_lsu_silva_23s_blast_align_len',\n",
       " 'tree_gf_lsu_silva_23s_blast_bitscore',\n",
       " 'tree_gf_lsu_silva_23s_blast_evalue',\n",
       " 'tree_gf_lsu_silva_23s_blast_perc_identity',\n",
       " 'tree_gf_lsu_silva_23s_blast_subject_id',\n",
       " 'tree_gf_lsu_silva_23s_taxonomy',\n",
       " 'tree_gf_mean_contig_length',\n",
       " 'tree_gf_mean_scaffold_length',\n",
       " 'tree_gf_mimag_high_quality',\n",
       " 'tree_gf_mimag_low_quality',\n",
       " 'tree_gf_mimag_medium_quality',\n",
       " 'tree_gf_n50_contigs',\n",
       " 'tree_gf_n50_scaffolds',\n",
       " 'tree_gf_ncbi_assembly_level',\n",
       " 'tree_gf_ncbi_assembly_name',\n",
       " 'tree_gf_ncbi_assembly_type',\n",
       " 'tree_gf_ncbi_bioproject',\n",
       " 'tree_gf_ncbi_biosample',\n",
       " 'tree_gf_ncbi_contig_count',\n",
       " 'tree_gf_ncbi_contig_n50',\n",
       " 'tree_gf_ncbi_country',\n",
       " 'tree_gf_ncbi_date',\n",
       " 'tree_gf_ncbi_genbank_assembly_accession',\n",
       " 'tree_gf_ncbi_genome_category',\n",
       " 'tree_gf_ncbi_genome_representation',\n",
       " 'tree_gf_ncbi_isolate',\n",
       " 'tree_gf_ncbi_isolation_source',\n",
       " 'tree_gf_ncbi_lat_lon',\n",
       " 'tree_gf_ncbi_molecule_count',\n",
       " 'tree_gf_ncbi_ncrna_count',\n",
       " 'tree_gf_ncbi_organism_name',\n",
       " 'tree_gf_ncbi_protein_count',\n",
       " 'tree_gf_ncbi_refseq_category',\n",
       " 'tree_gf_ncbi_rrna_count',\n",
       " 'tree_gf_ncbi_scaffold_count',\n",
       " 'tree_gf_ncbi_scaffold_l50',\n",
       " 'tree_gf_ncbi_scaffold_n50',\n",
       " 'tree_gf_ncbi_scaffold_n75',\n",
       " 'tree_gf_ncbi_scaffold_n90',\n",
       " 'tree_gf_ncbi_seq_rel_date',\n",
       " 'tree_gf_ncbi_spanned_gaps',\n",
       " 'tree_gf_ncbi_species_taxid',\n",
       " 'tree_gf_ncbi_ssu_count',\n",
       " 'tree_gf_ncbi_strain_identifiers',\n",
       " 'tree_gf_ncbi_submitter',\n",
       " 'tree_gf_ncbi_taxid',\n",
       " 'tree_gf_ncbi_taxonomy',\n",
       " 'tree_gf_ncbi_taxonomy_unfiltered',\n",
       " 'tree_gf_ncbi_total_gap_length',\n",
       " 'tree_gf_ncbi_total_length',\n",
       " 'tree_gf_ncbi_translation_table',\n",
       " 'tree_gf_ncbi_trna_count',\n",
       " 'tree_gf_ncbi_type_material_designation',\n",
       " 'tree_gf_ncbi_ungapped_length',\n",
       " 'tree_gf_ncbi_unspanned_gaps',\n",
       " 'tree_gf_ncbi_wgs_master',\n",
       " 'tree_gf_protein_count',\n",
       " 'tree_gf_scaffold_count',\n",
       " 'tree_gf_ssu_contig_len',\n",
       " 'tree_gf_ssu_count',\n",
       " 'tree_gf_ssu_gg_blast_align_len',\n",
       " 'tree_gf_ssu_gg_blast_bitscore',\n",
       " 'tree_gf_ssu_gg_blast_evalue',\n",
       " 'tree_gf_ssu_gg_blast_perc_identity',\n",
       " 'tree_gf_ssu_gg_blast_subject_id',\n",
       " 'tree_gf_ssu_gg_taxonomy',\n",
       " 'tree_gf_ssu_length',\n",
       " 'tree_gf_ssu_query_id',\n",
       " 'tree_gf_ssu_silva_blast_align_len',\n",
       " 'tree_gf_ssu_silva_blast_bitscore',\n",
       " 'tree_gf_ssu_silva_blast_evalue',\n",
       " 'tree_gf_ssu_silva_blast_perc_identity',\n",
       " 'tree_gf_ssu_silva_blast_subject_id',\n",
       " 'tree_gf_ssu_silva_taxonomy',\n",
       " 'tree_gf_total_gap_length',\n",
       " 'tree_gf_trna_aa_count',\n",
       " 'tree_gf_trna_count',\n",
       " 'tree_gf_trna_selenocysteine_count',\n",
       " 'dataset',\n",
       " 'truth',\n",
       " 'dataset_cat']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_type_1_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['hits',\n",
    " 'percent_coverage',\n",
    " 'mean_coverage',\n",
    " 'sd_coverage',\n",
    " 'percent_binned_coverage',\n",
    " 'mean_binned_coverage',\n",
    " 'sd_binned_coverage',\n",
    " 'expected_percent_coverage',\n",
    " 'shannon_entropy',\n",
    " 'percent_max_uncovered_region',\n",
    " 'largest_pileup',\n",
    " 'largest_binned_pileup',\n",
    " 'gc_content',\n",
    " 'total_genome_length',\n",
    " 'ungapped_genome_length',\n",
    " 'num_n_groups',\n",
    " 'consecutive_ns',\n",
    " 'tree_dist',\n",
    " 'tree_top_dist',\n",
    " 'gf_checkm_completeness',\n",
    " 'gf_checkm_contamination'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    hits  percent_coverage  mean_coverage    sd_coverage  \\\n",
      "dataset                                                                    \n",
      "dual_index       1734304         28.062051      88.341678     840.304259   \n",
      "gis_20         361319935         40.965084   11045.607897  214833.055608   \n",
      "hmp_even        26120868         48.138912     588.211176   14515.805304   \n",
      "hmp_staggered   13987473         23.541141     275.052218    9609.165257   \n",
      "mbarc_26        89680807         32.067000    6017.729981   16506.313587   \n",
      "zymo_even       10317373         19.231281     485.308514    5010.760035   \n",
      "zymo_log       133887236         13.417510    4209.986755   65399.745693   \n",
      "\n",
      "               percent_binned_coverage  mean_binned_coverage  \\\n",
      "dataset                                                        \n",
      "dual_index                     45.7004              173.4298   \n",
      "gis_20                         69.4328            36131.9216   \n",
      "hmp_even                      100.7977             2612.0792   \n",
      "hmp_staggered                  62.3441             1398.7440   \n",
      "mbarc_26                       42.1304             8968.0651   \n",
      "zymo_even                      33.6067             1031.7351   \n",
      "zymo_log                       30.3834            13388.6801   \n",
      "\n",
      "               sd_binned_coverage  expected_percent_coverage  shannon_entropy  \\\n",
      "dataset                                                                         \n",
      "dual_index            1702.960876                  52.153433       179.823230   \n",
      "gis_20              550476.441207                1997.584353       455.353938   \n",
      "hmp_even             42566.330971                 321.571858       410.359824   \n",
      "hmp_staggered        29917.616720                 169.792360       225.185784   \n",
      "mbarc_26             24474.325905                 148.190806       258.978773   \n",
      "zymo_even             9718.049812                 142.845271       179.112161   \n",
      "zymo_log            144636.955753                 618.069370       146.651949   \n",
      "\n",
      "               percent_max_uncovered_region  ...    gc_content  \\\n",
      "dataset                                      ...                 \n",
      "dual_index                     12865.579866  ...   8153.139975   \n",
      "gis_20                         14008.598856  ...   9984.697541   \n",
      "hmp_even                       14694.308894  ...  11394.495270   \n",
      "hmp_staggered                  14745.911165  ...  11069.700191   \n",
      "mbarc_26                       10447.003019  ...   7205.804696   \n",
      "zymo_even                      13094.897772  ...   8496.605595   \n",
      "zymo_log                       13270.054093  ...   8595.051518   \n",
      "\n",
      "               total_genome_length  ungapped_genome_length  num_n_groups  \\\n",
      "dataset                                                                    \n",
      "dual_index             66185721944             66060166994       1273492   \n",
      "gis_20                 80325904277             80182860947       1712365   \n",
      "hmp_even               89611972578             89445493597       2221353   \n",
      "hmp_staggered          87510930871             87349093800       2117274   \n",
      "mbarc_26               56988763472             56870883734       1268256   \n",
      "zymo_even              67343881866             67214666035       1334836   \n",
      "zymo_log               68232051912             68102146950       1357088   \n",
      "\n",
      "               consecutive_ns   tree_dist  tree_top_dist  \\\n",
      "dataset                                                    \n",
      "dual_index           13050147  1921.51874        31667.0   \n",
      "gis_20               13403030  2236.04027        35668.0   \n",
      "hmp_even             14826389  2879.85512        39688.0   \n",
      "hmp_staggered        14644311  2784.11203        38917.0   \n",
      "mbarc_26             11027610  1578.82674        27770.0   \n",
      "zymo_even            13134779  2022.09748        32730.0   \n",
      "zymo_log             13159080  2101.82460        33029.0   \n",
      "\n",
      "               gf_checkm_completeness  gf_checkm_contamination  truth  \n",
      "dataset                                                                \n",
      "dual_index                 1554894.59                 14666.02     19  \n",
      "gis_20                     1832452.12                 18495.29     19  \n",
      "hmp_even                   2091061.88                 22515.26     21  \n",
      "hmp_staggered              2034855.73                 21900.10     21  \n",
      "mbarc_26                   1317350.91                 13451.00     26  \n",
      "zymo_even                  1609169.63                 15387.32      8  \n",
      "zymo_log                   1624968.18                 15760.26      8  \n",
      "\n",
      "[7 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "X_type_1 = df_type_1_features[features + [\"assembly_accession\", \"dataset\", \"truth\", \"dataset_cat\"]]\n",
    "                                                 \n",
    "X_type_1 = X_type_1.replace([np.inf, -np.inf], np.nan)\n",
    "X_type_1 = X_type_1.dropna()\n",
    "\n",
    "print(X_type_1.groupby('dataset').sum())\n",
    "\n",
    "y = X_type_1[\"truth\"]\n",
    "X = X_type_1.loc[:, X_type_1.columns.difference([\"assembly_accession\", \"dataset\", \"dataset_cat\", \"truth\"])]\n",
    "\n",
    "X_type_1.to_csv(\"../data/type_1.extra.tree.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhillmann/.conda/envs/tpot-cuml/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhillmann/.conda/envs/tpot-cuml/lib/python3.7/site-packages/tpot/builtins/one_hot_encoder.py:216: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def __init__(self, categorical_features='auto', dtype=np.float,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mTPOTClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpopulation_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moffspring_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmutation_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcrossover_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msubsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_time_mins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_eval_time_mins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mconfig_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtemplate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0muse_dask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mperiodic_checkpoint_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mearly_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdisable_update_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlog_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      TPOT estimator for classification problems.\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Set up the genetic programming algorithm for pipeline optimization.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "generations: int or None, optional (default: 100)\n",
       "    Number of iterations to the run pipeline optimization process.\n",
       "    It must be a positive number or None. If None, the parameter\n",
       "    max_time_mins must be defined as the runtime limit.\n",
       "    Generally, TPOT will work better when you give it more generations (and\n",
       "    therefore time) to optimize the pipeline. TPOT will evaluate\n",
       "    POPULATION_SIZE + GENERATIONS x OFFSPRING_SIZE pipelines in total.\n",
       "population_size: int, optional (default: 100)\n",
       "    Number of individuals to retain in the GP population every generation.\n",
       "    Generally, TPOT will work better when you give it more individuals\n",
       "    (and therefore time) to optimize the pipeline. TPOT will evaluate\n",
       "    POPULATION_SIZE + GENERATIONS x OFFSPRING_SIZE pipelines in total.\n",
       "offspring_size: int, optional (default: None)\n",
       "    Number of offspring to produce in each GP generation.\n",
       "    By default, offspring_size = population_size.\n",
       "mutation_rate: float, optional (default: 0.9)\n",
       "    Mutation rate for the genetic programming algorithm in the range [0.0, 1.0].\n",
       "    This parameter tells the GP algorithm how many pipelines to apply random\n",
       "    changes to every generation. We recommend using the default parameter unless\n",
       "    you understand how the mutation rate affects GP algorithms.\n",
       "crossover_rate: float, optional (default: 0.1)\n",
       "    Crossover rate for the genetic programming algorithm in the range [0.0, 1.0].\n",
       "    This parameter tells the genetic programming algorithm how many pipelines to\n",
       "    \"breed\" every generation. We recommend using the default parameter unless you\n",
       "    understand how the mutation rate affects GP algorithms.\n",
       "scoring: string or callable, optional\n",
       "    Function used to evaluate the quality of a given pipeline for the\n",
       "    problem. By default, accuracy is used for classification problems and\n",
       "    mean squared error (MSE) for regression problems.\n",
       "\n",
       "    Offers the same options as sklearn.model_selection.cross_val_score as well as\n",
       "    a built-in score 'balanced_accuracy'. Classification metrics:\n",
       "\n",
       "    ['accuracy', 'adjusted_rand_score', 'average_precision', 'balanced_accuracy',\n",
       "    'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted',\n",
       "    'precision', 'precision_macro', 'precision_micro', 'precision_samples',\n",
       "    'precision_weighted', 'recall', 'recall_macro', 'recall_micro',\n",
       "    'recall_samples', 'recall_weighted', 'roc_auc']\n",
       "\n",
       "    Regression metrics:\n",
       "\n",
       "    ['neg_median_absolute_error', 'neg_mean_absolute_error',\n",
       "    'neg_mean_squared_error', 'r2']\n",
       "cv: int or cross-validation generator, optional (default: 5)\n",
       "    If CV is a number, then it is the number of folds to evaluate each\n",
       "    pipeline over in k-fold cross-validation during the TPOT optimization\n",
       "     process. If it is an object then it is an object to be used as a\n",
       "     cross-validation generator.\n",
       "subsample: float, optional (default: 1.0)\n",
       "    Subsample ratio of the training instance. Setting it to 0.5 means that TPOT\n",
       "    randomly collects half of training samples for pipeline optimization process.\n",
       "n_jobs: int, optional (default: 1)\n",
       "    Number of CPUs for evaluating pipelines in parallel during the TPOT\n",
       "    optimization process. Assigning this to -1 will use as many cores as available\n",
       "    on the computer. For n_jobs below -1, (n_cpus + 1 + n_jobs) are used.\n",
       "    Thus for n_jobs = -2, all CPUs but one are used.\n",
       "max_time_mins: int, optional (default: None)\n",
       "    How many minutes TPOT has to optimize the pipeline.\n",
       "    If not None, this setting will allow TPOT to run until max_time_mins minutes\n",
       "    elapsed and then stop. TPOT will stop earlier if generationsis set and all\n",
       "    generations are already evaluated.\n",
       "max_eval_time_mins: float, optional (default: 5)\n",
       "    How many minutes TPOT has to optimize a single pipeline.\n",
       "    Setting this parameter to higher values will allow TPOT to explore more\n",
       "    complex pipelines, but will also allow TPOT to run longer.\n",
       "random_state: int, optional (default: None)\n",
       "    Random number generator seed for TPOT. Use this parameter to make sure\n",
       "    that TPOT will give you the same results each time you run it against the\n",
       "    same data set with that seed.\n",
       "config_dict: a Python dictionary or string, optional (default: None)\n",
       "    Python dictionary:\n",
       "        A dictionary customizing the operators and parameters that\n",
       "        TPOT uses in the optimization process.\n",
       "        For examples, see config_regressor.py and config_classifier.py\n",
       "    Path for configuration file:\n",
       "        A path to a configuration file for customizing the operators and parameters that\n",
       "        TPOT uses in the optimization process.\n",
       "        For examples, see config_regressor.py and config_classifier.py\n",
       "    String 'TPOT light':\n",
       "        TPOT uses a light version of operator configuration dictionary instead of\n",
       "        the default one.\n",
       "    String 'TPOT MDR':\n",
       "        TPOT uses a list of TPOT-MDR operator configuration dictionary instead of\n",
       "        the default one.\n",
       "    String 'TPOT sparse':\n",
       "        TPOT uses a configuration dictionary with a one-hot-encoder and the\n",
       "        operators normally included in TPOT that also support sparse matrices.\n",
       "    String 'TPOT NN':\n",
       "        TPOT uses a configuration dictionary for PyTorch neural network classifiers\n",
       "        included in `tpot.nn`.\n",
       "template: string (default: None)\n",
       "    Template of predefined pipeline structure. The option is for specifying a desired structure\n",
       "    for the machine learning pipeline evaluated in TPOT. So far this option only supports\n",
       "    linear pipeline structure. Each step in the pipeline should be a main class of operators\n",
       "    (Selector, Transformer, Classifier or Regressor) or a specific operator\n",
       "    (e.g. SelectPercentile) defined in TPOT operator configuration. If one step is a main class,\n",
       "    TPOT will randomly assign all subclass operators (subclasses of SelectorMixin,\n",
       "    TransformerMixin, ClassifierMixin or RegressorMixin in scikit-learn) to that step.\n",
       "    Steps in the template are delimited by \"-\", e.g. \"SelectPercentile-Transformer-Classifier\".\n",
       "    By default value of template is None, TPOT generates tree-based pipeline randomly.\n",
       "warm_start: bool, optional (default: False)\n",
       "    Flag indicating whether the TPOT instance will reuse the population from\n",
       "    previous calls to fit().\n",
       "memory: a Memory object or string, optional (default: None)\n",
       "    If supplied, pipeline will cache each transformer after calling fit. This feature\n",
       "    is used to avoid computing the fit transformers within a pipeline if the parameters\n",
       "    and input data are identical with another fitted pipeline during optimization process.\n",
       "    String 'auto':\n",
       "        TPOT uses memory caching with a temporary directory and cleans it up upon shutdown.\n",
       "    String path of a caching directory\n",
       "        TPOT uses memory caching with the provided directory and TPOT does NOT clean\n",
       "        the caching directory up upon shutdown. If the directory does not exist, TPOT will\n",
       "        create it.\n",
       "    Memory object:\n",
       "        TPOT uses the instance of joblib.Memory for memory caching,\n",
       "        and TPOT does NOT clean the caching directory up upon shutdown.\n",
       "    None:\n",
       "        TPOT does not use memory caching.\n",
       "use_dask: boolean, default False\n",
       "    Whether to use Dask-ML's pipeline optimizations. This avoid re-fitting\n",
       "    the same estimator on the same split of data multiple times. It\n",
       "    will also provide more detailed diagnostics when using Dask's\n",
       "    distributed scheduler.\n",
       "\n",
       "    See `avoid repeated work <https://dask-ml.readthedocs.io/en/latest/hyper-parameter-search.html#avoid-repeated-work>`__\n",
       "    for more details.\n",
       "periodic_checkpoint_folder: path string, optional (default: None)\n",
       "    If supplied, a folder in which tpot will periodically save pipelines in pareto front so far while optimizing.\n",
       "    Currently once per generation but not more often than once per 30 seconds.\n",
       "    Useful in multiple cases:\n",
       "        Sudden death before tpot could save optimized pipeline\n",
       "        Track its progress\n",
       "        Grab pipelines while it's still optimizing\n",
       "early_stop: int or None (default: None)\n",
       "    How many generations TPOT checks whether there is no improvement in optimization process.\n",
       "    End optimization process if there is no improvement in the set number of generations.\n",
       "verbosity: int, optional (default: 0)\n",
       "    How much information TPOT communicates while it's running.\n",
       "    0 = none, 1 = minimal, 2 = high, 3 = all.\n",
       "    A setting of 2 or higher will add a progress bar during the optimization procedure.\n",
       "disable_update_check: bool, optional (default: False)\n",
       "    Flag indicating whether the TPOT version checker should be disabled.\n",
       "log_file: string, io.TextIOWrapper or io.StringIO, optional (defaul: sys.stdout)\n",
       "    Save progress content to a file.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "None\n",
       "\u001b[0;31mFile:\u001b[0m           ~/.conda/envs/tpot-cuml/lib/python3.7/site-packages/tpot/tpot.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "\n",
    "\n",
    "?TPOTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhillmann/.conda/envs/tpot-cuml/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from tpot.config.classifier import classifier_config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'class_weight': 'balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_config_dict = {\n",
    "\n",
    "    # Classifiers\n",
    "    'sklearn.naive_bayes.GaussianNB': {\n",
    "    },\n",
    "\n",
    "    'sklearn.naive_bayes.BernoulliNB': {\n",
    "        'alpha': [1e-3, 1e-2, 1e-1, 1., 10., 100.],\n",
    "        'fit_prior': [True, False]\n",
    "    },\n",
    "\n",
    "    'sklearn.naive_bayes.MultinomialNB': {\n",
    "        'alpha': [1e-3, 1e-2, 1e-1, 1., 10., 100.],\n",
    "        'fit_prior': [True, False]\n",
    "    },\n",
    "\n",
    "    'sklearn.tree.DecisionTreeClassifier': {\n",
    "        'criterion': [\"gini\", \"entropy\"],\n",
    "        'max_depth': range(1, 11),\n",
    "        'min_samples_split': range(2, 21),\n",
    "        'min_samples_leaf': range(1, 21)\n",
    "    },\n",
    "\n",
    "    'sklearn.ensemble.ExtraTreesClassifier': {\n",
    "        'n_estimators': [100],\n",
    "        'criterion': [\"gini\", \"entropy\"],\n",
    "        'max_features': np.arange(0.05, 1.01, 0.05),\n",
    "        'min_samples_split': range(2, 21),\n",
    "        'min_samples_leaf': range(1, 21),\n",
    "        'bootstrap': [True, False],\n",
    "        'class_weight': ['balanced', 'balanced_subsample', None]\n",
    "    },\n",
    "\n",
    "    'sklearn.ensemble.RandomForestClassifier': {\n",
    "        'n_estimators': [100],\n",
    "        'criterion': [\"gini\", \"entropy\"],\n",
    "        'max_features': np.arange(0.05, 1.01, 0.05),\n",
    "        'min_samples_split': range(2, 21),\n",
    "        'min_samples_leaf':  range(1, 21),\n",
    "        'bootstrap': [True, False],\n",
    "        'class_weight': ['balanced', 'balanced_subsample', None]\n",
    "    },\n",
    "\n",
    "    'sklearn.ensemble.GradientBoostingClassifier': {\n",
    "        'n_estimators': [100],\n",
    "        'learning_rate': [1e-3, 1e-2, 1e-1, 0.5, 1.],\n",
    "        'max_depth': range(1, 11),\n",
    "        'min_samples_split': range(2, 21),\n",
    "        'min_samples_leaf': range(1, 21),\n",
    "        'subsample': np.arange(0.05, 1.01, 0.05),\n",
    "        'max_features': np.arange(0.05, 1.01, 0.05)\n",
    "    },\n",
    "\n",
    "    'sklearn.neighbors.KNeighborsClassifier': {\n",
    "        'n_neighbors': range(1, 101),\n",
    "        'weights': [\"uniform\", \"distance\"],\n",
    "        'p': [1, 2]\n",
    "    },\n",
    "\n",
    "    'sklearn.svm.LinearSVC': {\n",
    "        'penalty': [\"l1\", \"l2\"],\n",
    "        'loss': [\"hinge\", \"squared_hinge\"],\n",
    "        'dual': [True, False],\n",
    "        'tol': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1],\n",
    "        'C': [1e-4, 1e-3, 1e-2, 1e-1, 0.5, 1., 5., 10., 15., 20., 25.]\n",
    "    },\n",
    "\n",
    "    'sklearn.linear_model.LogisticRegression': {\n",
    "        'penalty': [\"l1\", \"l2\"],\n",
    "        'C': [1e-4, 1e-3, 1e-2, 1e-1, 0.5, 1., 5., 10., 15., 20., 25.],\n",
    "        'dual': [True, False],\n",
    "        'class_weight': ['balanced', None]\n",
    "    },\n",
    "\n",
    "    'xgboost.XGBClassifier': {\n",
    "        'n_estimators': [100],\n",
    "        'max_depth': range(1, 11),\n",
    "        'learning_rate': [1e-3, 1e-2, 1e-1, 0.5, 1.],\n",
    "        'subsample': np.arange(0.05, 1.01, 0.05),\n",
    "        'min_child_weight': range(1, 21),\n",
    "        'n_jobs': [1],\n",
    "        'verbosity': [0],\n",
    "        'scale_pos_weight': [1, 10, 25, 50, 75, 99, 100, 1000]\n",
    "    },\n",
    "\n",
    "    'sklearn.linear_model.SGDClassifier': {\n",
    "        'loss': ['log', 'hinge', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "        'penalty': ['elasticnet'],\n",
    "        'alpha': [0.0, 0.01, 0.001],\n",
    "        'learning_rate': ['invscaling', 'constant'],\n",
    "        'fit_intercept': [True, False],\n",
    "        'l1_ratio': [0.25, 0.0, 1.0, 0.75, 0.5],\n",
    "        'eta0': [0.1, 1.0, 0.01],\n",
    "        'power_t': [0.5, 0.0, 1.0, 0.1, 100.0, 10.0, 50.0]\n",
    "    },\n",
    "\n",
    "    'sklearn.neural_network.MLPClassifier': {\n",
    "        'alpha': [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "        'learning_rate_init': [1e-3, 1e-2, 1e-1, 0.5, 1.]\n",
    "    },\n",
    "\n",
    "    # Preprocesssors\n",
    "    'sklearn.preprocessing.Binarizer': {\n",
    "        'threshold': np.arange(0.0, 1.01, 0.05)\n",
    "    },\n",
    "\n",
    "    'sklearn.decomposition.FastICA': {\n",
    "        'tol': np.arange(0.0, 1.01, 0.05)\n",
    "    },\n",
    "\n",
    "    'sklearn.cluster.FeatureAgglomeration': {\n",
    "        'linkage': ['ward', 'complete', 'average'],\n",
    "        'affinity': ['euclidean', 'l1', 'l2', 'manhattan', 'cosine']\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.MaxAbsScaler': {\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.MinMaxScaler': {\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.Normalizer': {\n",
    "        'norm': ['l1', 'l2', 'max']\n",
    "    },\n",
    "\n",
    "    'sklearn.kernel_approximation.Nystroem': {\n",
    "        'kernel': ['rbf', 'cosine', 'chi2', 'laplacian', 'polynomial', 'poly', 'linear', 'additive_chi2', 'sigmoid'],\n",
    "        'gamma': np.arange(0.0, 1.01, 0.05),\n",
    "        'n_components': range(1, 11)\n",
    "    },\n",
    "\n",
    "    'sklearn.decomposition.PCA': {\n",
    "        'svd_solver': ['randomized'],\n",
    "        'iterated_power': range(1, 11)\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.PolynomialFeatures': {\n",
    "        'degree': [2],\n",
    "        'include_bias': [False],\n",
    "        'interaction_only': [False]\n",
    "    },\n",
    "\n",
    "    'sklearn.kernel_approximation.RBFSampler': {\n",
    "        'gamma': np.arange(0.0, 1.01, 0.05)\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.RobustScaler': {\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.StandardScaler': {\n",
    "    },\n",
    "\n",
    "    'tpot.builtins.ZeroCount': {\n",
    "    },\n",
    "\n",
    "    'tpot.builtins.OneHotEncoder': {\n",
    "        'minimum_fraction': [0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "        'sparse': [False],\n",
    "        'threshold': [10]\n",
    "    },\n",
    "\n",
    "    # Selectors\n",
    "    'sklearn.feature_selection.SelectFwe': {\n",
    "        'alpha': np.arange(0, 0.05, 0.001),\n",
    "        'score_func': {\n",
    "            'sklearn.feature_selection.f_classif': None\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'sklearn.feature_selection.SelectPercentile': {\n",
    "        'percentile': range(1, 100),\n",
    "        'score_func': {\n",
    "            'sklearn.feature_selection.f_classif': None\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'sklearn.feature_selection.VarianceThreshold': {\n",
    "        'threshold': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.2]\n",
    "    },\n",
    "\n",
    "    'sklearn.feature_selection.RFE': {\n",
    "        'step': np.arange(0.05, 1.01, 0.05),\n",
    "        'estimator': {\n",
    "            'sklearn.ensemble.ExtraTreesClassifier': {\n",
    "                'n_estimators': [100],\n",
    "                'criterion': ['gini', 'entropy'],\n",
    "                'max_features': np.arange(0.05, 1.01, 0.05),\n",
    "                'class_weight': ['balanced', 'balanced_subsample', None]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'sklearn.feature_selection.SelectFromModel': {\n",
    "        'threshold': np.arange(0, 1.01, 0.05),\n",
    "        'estimator': {\n",
    "            'sklearn.ensemble.ExtraTreesClassifier': {\n",
    "                'n_estimators': [100],\n",
    "                'criterion': ['gini', 'entropy'],\n",
    "                'max_features': np.arange(0.05, 1.01, 0.05),\n",
    "                'class_weight': ['balanced', 'balanced_subsample', None]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7601246105919003\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: xgboost.XGBClassifier is not available and will not be used by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae79b5647ce4faf99075e88df08cfca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/120 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "\n",
    "\n",
    "tpot = TPOTClassifier(generations=5, population_size=20, verbosity=2, random_state=42, n_jobs=40, config_dict=classifier_config_dict, cv=CV, scoring='f1')\n",
    "tpot.fit(X, y)\n",
    "# print(tpot.score(X_test, y_test))\n",
    "tpot.export('tpot_iris_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhillmann/.conda/envs/tpot-cuml/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from tpot.export_utils import set_param_recursive\n",
    "\n",
    "# Average CV score on the training set was: 0.4020165729147765\n",
    "exported_pipeline = make_pipeline(\n",
    "    MaxAbsScaler(),\n",
    "    RandomForestClassifier(bootstrap=True, class_weight=\"balanced_subsample\", criterion=\"gini\", max_features=0.6000000000000001, min_samples_leaf=9, min_samples_split=9, n_estimators=100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhillmann/.conda/envs/tpot-cuml/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41025641025641024]\n",
      "[0.41025641025641024, 0.39999999999999997]\n",
      "[0.41025641025641024, 0.39999999999999997, 0.23999999999999996]\n",
      "[0.41025641025641024, 0.39999999999999997, 0.23999999999999996, 0.2777777777777778]\n",
      "[0.41025641025641024, 0.39999999999999997, 0.23999999999999996, 0.2777777777777778, 0.4864864864864864]\n"
     ]
    }
   ],
   "source": [
    "classifiers = []\n",
    "results = []\n",
    "for i, (train, test) in enumerate(CV.split(X, y)):\n",
    "    clf = RandomForestClassifier(bootstrap=True, class_weight=\"balanced_subsample\", criterion=\"gini\", max_features=0.6000000000000001, min_samples_leaf=9, min_samples_split=9, n_estimators=100)\n",
    "    clf.fit(X.loc[train], y.loc[train])\n",
    "    classifiers.append(clf)\n",
    "    y_pred = clf.predict(X.loc[test])\n",
    "    results.append(f1_score(y.loc[test], y_pred))\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.mean(np.array(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = (np.sum(y) / y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhillmann/.conda/envs/tpot-cuml/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3588082416743853"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhillmann/.conda/envs/tpot-cuml/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'oob_score_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-c2b6a1bb2634>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moob_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'oob_score_'"
     ]
    }
   ],
   "source": [
    "clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6948640483383687"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y, clf.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3581772339666864"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f - q) / (1 - q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tpot-cuml]",
   "language": "python",
   "name": "conda-env-.conda-tpot-cuml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
