{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib: 3.3.4\n",
      "numpy     : 1.20.1\n",
      "pandas    : 1.2.2\n",
      "seaborn   : 0.11.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "np.random.seed(930525)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "warnings.simplefilter('once')\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhillmann/.conda/envs/tpot/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhillmann/.conda/envs/tpot/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/home/bhillmann/.conda/envs/tpot/lib/python3.8/site-packages/tpot/builtins/one_hot_encoder.py:216: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def __init__(self, categorical_features='auto', dtype=np.float,\n",
      "/home/bhillmann/.conda/envs/tpot/lib/python3.8/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhillmann/.conda/envs/tpot/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/home/bhillmann/.conda/envs/tpot/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3155: DtypeWarning: Columns (47,49,55,56,57,58,70,83,95,96,100,103,104,108,109) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df_type_1_features = pd.read_csv(\"../notebooks/strains.dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['hits',\n",
    " 'percent_coverage',\n",
    " 'mean_coverage',\n",
    " 'sd_coverage',\n",
    " 'percent_binned_coverage',\n",
    " 'mean_binned_coverage',\n",
    " 'sd_binned_coverage',\n",
    " 'expected_percent_coverage',\n",
    " 'shannon_entropy',\n",
    " 'percent_max_uncovered_region',\n",
    " 'largest_pileup',\n",
    " 'largest_binned_pileup',\n",
    " 'gc_content',\n",
    " 'total_genome_length',\n",
    " 'ungapped_genome_length',\n",
    " 'num_n_groups',\n",
    " 'consecutive_ns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhillmann/.conda/envs/tpot/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    hits  percent_coverage  mean_coverage    sd_coverage  \\\n",
      "dataset                                                                    \n",
      "dual_index       1579150         24.456719      77.797533     829.716959   \n",
      "gis_20         362361709         42.052061   11047.181289  215421.796525   \n",
      "hmp_even        25248883         44.848096     565.878501   14545.256815   \n",
      "hmp_staggered   13716590         21.731233     267.918649    9666.614768   \n",
      "mbarc_26        93698669         32.331114    5516.780499   15708.117984   \n",
      "zymo_even        9230086         16.898517     434.592579    5085.070763   \n",
      "zymo_log       125214913         12.027565    3907.630176   64798.277804   \n",
      "\n",
      "               percent_binned_coverage  mean_binned_coverage  \\\n",
      "dataset                                                        \n",
      "dual_index                     41.2142              157.9145   \n",
      "gis_20                         69.4660            36236.1049   \n",
      "hmp_even                       95.5295             2524.8810   \n",
      "hmp_staggered                  58.5772             1371.6494   \n",
      "mbarc_26                       42.1899             9369.8532   \n",
      "zymo_even                      30.8383              923.0067   \n",
      "zymo_log                       28.1510            12521.4448   \n",
      "\n",
      "               sd_binned_coverage  expected_percent_coverage  shannon_entropy  \\\n",
      "dataset                                                                         \n",
      "dual_index            1688.833978                  47.648222       165.292793   \n",
      "gis_20              550725.175298                2013.529933       454.867872   \n",
      "hmp_even             42865.926522                 317.839053       392.041458   \n",
      "hmp_staggered        30194.132235                 169.019273       215.900708   \n",
      "mbarc_26             24265.276114                 144.832836       256.745315   \n",
      "zymo_even             9804.494358                 140.309648       163.245335   \n",
      "zymo_log            142507.428860                 625.398431       138.257369   \n",
      "\n",
      "               percent_max_uncovered_region  largest_pileup  \\\n",
      "dataset                                                       \n",
      "dual_index                     12893.929290           71012   \n",
      "gis_20                         14047.576487        17010239   \n",
      "hmp_even                       14741.800261         1961899   \n",
      "hmp_staggered                  14771.282487         1530028   \n",
      "mbarc_26                       10442.374404          706128   \n",
      "zymo_even                      13099.564106          416095   \n",
      "zymo_log                       13276.277625         6522230   \n",
      "\n",
      "               largest_binned_pileup    gc_content  total_genome_length  \\\n",
      "dataset                                                                   \n",
      "dual_index                     86197   8148.335736          65584903721   \n",
      "gis_20                      26405199   9989.702167          79663673284   \n",
      "hmp_even                     2483391  11386.917085          88870525797   \n",
      "hmp_staggered                1841305  11060.956907          86797604430   \n",
      "mbarc_26                      803617   7202.494273          56682782838   \n",
      "zymo_even                     508820   8491.361734          66787983128   \n",
      "zymo_log                     7286972   8591.395106          67606471034   \n",
      "\n",
      "               ungapped_genome_length  num_n_groups  consecutive_ns  truth  \n",
      "dataset                                                                     \n",
      "dual_index                65389300408       1289197        23643822     19  \n",
      "gis_20                    79509485955       1755125        18221804     19  \n",
      "hmp_even                  88632115190       2246399        25314759     21  \n",
      "hmp_staggered             86564123943       2133437        25101349     21  \n",
      "mbarc_26                  56490731031       1289425        22070769     26  \n",
      "zymo_even                 66590254463       1341771        23708014      8  \n",
      "zymo_log                  67407584854       1370070        23741238      8  \n"
     ]
    }
   ],
   "source": [
    "X_type_1 = df_type_1_features[features + [\"assembly_accession\", \"dataset\", \"truth\"]]\n",
    "                                                 \n",
    "X_type_1 = X_type_1.replace([np.inf, -np.inf], np.nan)\n",
    "X_type_1 = X_type_1.dropna()\n",
    "\n",
    "print(X_type_1.groupby('dataset').sum())\n",
    "\n",
    "y = X_type_1[\"truth\"]\n",
    "X_type_1 = X_type_1.loc[:, X_type_1.columns.difference([\"assembly_accession\", \"dataset\"])]\n",
    "\n",
    "X_type_1.to_csv(\"../data/type_1.extra.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    hits  percent_coverage  mean_coverage    sd_coverage  \\\n",
      "dataset                                                                    \n",
      "dual_index       1579150         24.456719      77.797533     829.716959   \n",
      "gis_20         362361709         42.052061   11047.181289  215421.796525   \n",
      "hmp_even        25248883         44.848096     565.878501   14545.256815   \n",
      "hmp_staggered   13716590         21.731233     267.918649    9666.614768   \n",
      "mbarc_26        93698669         32.331114    5516.780499   15708.117984   \n",
      "zymo_even        9230086         16.898517     434.592579    5085.070763   \n",
      "zymo_log       125214913         12.027565    3907.630176   64798.277804   \n",
      "\n",
      "               percent_binned_coverage  mean_binned_coverage  \\\n",
      "dataset                                                        \n",
      "dual_index                     41.2142              157.9145   \n",
      "gis_20                         69.4660            36236.1049   \n",
      "hmp_even                       95.5295             2524.8810   \n",
      "hmp_staggered                  58.5772             1371.6494   \n",
      "mbarc_26                       42.1899             9369.8532   \n",
      "zymo_even                      30.8383              923.0067   \n",
      "zymo_log                       28.1510            12521.4448   \n",
      "\n",
      "               sd_binned_coverage  expected_percent_coverage  shannon_entropy  \\\n",
      "dataset                                                                         \n",
      "dual_index            1688.833978                  47.648222       165.292793   \n",
      "gis_20              550725.175298                2013.529933       454.867872   \n",
      "hmp_even             42865.926522                 317.839053       392.041458   \n",
      "hmp_staggered        30194.132235                 169.019273       215.900708   \n",
      "mbarc_26             24265.276114                 144.832836       256.745315   \n",
      "zymo_even             9804.494358                 140.309648       163.245335   \n",
      "zymo_log            142507.428860                 625.398431       138.257369   \n",
      "\n",
      "               percent_max_uncovered_region  largest_pileup  \\\n",
      "dataset                                                       \n",
      "dual_index                     12893.929290           71012   \n",
      "gis_20                         14047.576487        17010239   \n",
      "hmp_even                       14741.800261         1961899   \n",
      "hmp_staggered                  14771.282487         1530028   \n",
      "mbarc_26                       10442.374404          706128   \n",
      "zymo_even                      13099.564106          416095   \n",
      "zymo_log                       13276.277625         6522230   \n",
      "\n",
      "               largest_binned_pileup    gc_content  total_genome_length  \\\n",
      "dataset                                                                   \n",
      "dual_index                     86197   8148.335736          65584903721   \n",
      "gis_20                      26405199   9989.702167          79663673284   \n",
      "hmp_even                     2483391  11386.917085          88870525797   \n",
      "hmp_staggered                1841305  11060.956907          86797604430   \n",
      "mbarc_26                      803617   7202.494273          56682782838   \n",
      "zymo_even                     508820   8491.361734          66787983128   \n",
      "zymo_log                     7286972   8591.395106          67606471034   \n",
      "\n",
      "               ungapped_genome_length  num_n_groups  consecutive_ns  truth  \n",
      "dataset                                                                     \n",
      "dual_index                65389300408       1289197        23643822     19  \n",
      "gis_20                    79509485955       1755125        18221804     19  \n",
      "hmp_even                  88632115190       2246399        25314759     21  \n",
      "hmp_staggered             86564123943       2133437        25101349     21  \n",
      "mbarc_26                  56490731031       1289425        22070769     26  \n",
      "zymo_even                 66590254463       1341771        23708014      8  \n",
      "zymo_log                  67407584854       1370070        23741238      8  \n"
     ]
    }
   ],
   "source": [
    "X_type_1 = df_type_1_features[features + [\"assembly_accession\", \"dataset\", \"truth\"]]\n",
    "                                                 \n",
    "X_type_1 = X_type_1.replace([np.inf, -np.inf], np.nan)\n",
    "X_type_1 = X_type_1.dropna()\n",
    "\n",
    "print(X_type_1.groupby('dataset').sum())\n",
    "\n",
    "y = X_type_1[\"truth\"]\n",
    "X_type_1 = X_type_1.loc[:, X_type_1.columns.difference([\"assembly_accession\", \"dataset\", \"truth\"])]\n",
    "\n",
    "\n",
    "X_type_1_train, X_type_1_test, y_train, y_test = train_test_split(X_type_1, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhillmann/.conda/envs/tpot/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "Version 0.11.6.post3 of tpot is outdated. Version 0.11.7 was released Wednesday January 06, 2021.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df8523c161d4fee8ad63dd26dab93c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/300 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "A pipeline has not yet been optimized. Please call fit() first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-da13d2eb5466>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtpot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTPOTClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopulation_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtpot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_type_1_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/tpot/lib/python3.8/site-packages/tpot/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[1;32m    771\u001b[0m                     \u001b[0;31m# raise the exception if it's our last attempt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mattempt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattempts\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tpot/lib/python3.8/site-packages/tpot/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[1;32m    762\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_top_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_summary_of_best_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m                     \u001b[0;31m# Delete the temporary cache before exiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tpot/lib/python3.8/site-packages/tpot/base.py\u001b[0m in \u001b[0;36m_update_top_pipeline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# If user passes CTRL+C in initial generation, self._pareto_front (halloffame) shoule be not updated yet.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[0;31m# need raise RuntimeError because no pipeline has been optimized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'A pipeline has not yet been optimized. Please call fit() first.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_summary_of_best_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: A pipeline has not yet been optimized. Please call fit() first."
     ]
    }
   ],
   "source": [
    "tpot = TPOTClassifier(generations=5, population_size=50, verbosity=2, random_state=42, n_jobs=20)\n",
    "tpot.fit(X_type_1_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhillmann/.conda/envs/tpot/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "Version 0.11.6.post3 of tpot is outdated. Version 0.11.7 was released Wednesday January 06, 2021.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c5c967eba346e7a710a2d505c705ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/300 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -inf\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "There was an error in the TPOT optimization process. This could be because the data was not formatted properly, or because data for a regression problem was provided to the TPOTClassifier object. Please make sure you passed the data to TPOT correctly. If you enabled PyTorch estimators, please check the data requirements in the online documentation: https://epistasislab.github.io/tpot/using/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/tpot/lib/python3.8/site-packages/tpot/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 self._pop, _ = eaMuPlusLambda(\n\u001b[0m\u001b[1;32m    731\u001b[0m                     \u001b[0mpopulation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tpot/lib/python3.8/site-packages/tpot/gp_deap.py\u001b[0m in \u001b[0;36meaMuPlusLambda\u001b[0;34m(population, toolbox, mu, lambda_, cxpb, mutpb, ngen, pbar, stats, halloffame, verbose, per_generation_function, log_file)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mper_generation_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0mper_generation_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tpot/lib/python3.8/site-packages/tpot/base.py\u001b[0m in \u001b[0;36m_check_periodic_pipeline\u001b[0;34m(self, gen)\u001b[0m\n\u001b[1;32m   1051\u001b[0m         \"\"\"\n\u001b[0;32m-> 1052\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_top_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiodic_checkpoint_folder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tpot/lib/python3.8/site-packages/tpot/base.py\u001b[0m in \u001b[0;36m_update_top_pipeline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    837\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 raise RuntimeError('There was an error in the TPOT optimization '\n\u001b[0m\u001b[1;32m    839\u001b[0m                                    \u001b[0;34m'process. This could be because the data was '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: There was an error in the TPOT optimization process. This could be because the data was not formatted properly, or because data for a regression problem was provided to the TPOTClassifier object. Please make sure you passed the data to TPOT correctly. If you enabled PyTorch estimators, please check the data requirements in the online documentation: https://epistasislab.github.io/tpot/using/",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3320d979decd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtpot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTPOTClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopulation_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtpot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtpot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tpot_iris_pipeline.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tpot/lib/python3.8/site-packages/tpot/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[1;32m    771\u001b[0m                     \u001b[0;31m# raise the exception if it's our last attempt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mattempt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattempts\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tpot/lib/python3.8/site-packages/tpot/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[1;32m    762\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_top_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_summary_of_best_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m                     \u001b[0;31m# Delete the temporary cache before exiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tpot/lib/python3.8/site-packages/tpot/base.py\u001b[0m in \u001b[0;36m_update_top_pipeline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    836\u001b[0m                                                     error_score=\"raise\")\n\u001b[1;32m    837\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 raise RuntimeError('There was an error in the TPOT optimization '\n\u001b[0m\u001b[1;32m    839\u001b[0m                                    \u001b[0;34m'process. This could be because the data was '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m                                    \u001b[0;34m'not formatted properly, or because data for '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: There was an error in the TPOT optimization process. This could be because the data was not formatted properly, or because data for a regression problem was provided to the TPOTClassifier object. Please make sure you passed the data to TPOT correctly. If you enabled PyTorch estimators, please check the data requirements in the online documentation: https://epistasislab.github.io/tpot/using/"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data.astype(np.float64),\n",
    "    iris.target.astype(np.float64), train_size=0.75, test_size=0.25, random_state=42)\n",
    "\n",
    "tpot = TPOTClassifier(generations=5, population_size=50, verbosity=2, random_state=42, n_jobs=1)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))\n",
    "tpot.export('tpot_iris_pipeline.py')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tpot]",
   "language": "python",
   "name": "conda-env-.conda-tpot-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
