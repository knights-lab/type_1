{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_name = \"xgb_feature_selection\"\n",
    "\n",
    "from tpot.builtins import OneHotEncoder, StackingEstimator, ZeroCount\n",
    "from sklearn.feature_selection import VarianceThreshold, RFE\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "from sklearn.metrics import average_precision_score, plot_precision_recall_curve\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from tpot.builtins import StackingEstimator\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "logistic = LogisticRegression(penalty=\"l1\", solver=\"liblinear\", fit_intercept=True, dual=False, tol=0.001, class_weight=\"balanced\")\n",
    "\n",
    "\n",
    "pipe = (\n",
    "        VarianceThreshold(threshold=0.1),\n",
    "        ZeroCount(),\n",
    "        RFE(logistic),\n",
    "        XGBClassifier(learning_rate=0.01, max_depth=5, min_child_weight=13, n_estimators=100, n_jobs=1, scale_pos_weight=50, subsample=0.6500000000000001, verbosity=0),\n",
    ")\n",
    "#     clf = RandomForestClassifier(n_estimators=100, max_features=.2, min_samples_leaf=17, min_samples_split=9, bootstrap=False, criterion=\"gini\", class_weight=\"balanced_subsample\")\n",
    "#     clf = ExtraTreesClassifier(bootstrap=True, class_weight=None, criterion='entropy', max_features=0.8, min_samples_leaf=4, min_samples_split=20, n_estimators=100)\n",
    "#     clf = make_pipeline(*pipe)\n",
    "#     clf = make_pipeline(\n",
    "# #         MinMaxScaler(),\n",
    "# #         RFE(LogisticRegression(penalty=\"l1\", solver=\"liblinear\", fit_intercept=True, dual=False, tol=0.001, class_weight=\"balanced\")),\n",
    "#         StackingEstimator(estimator=XGBClassifier(learning_rate=0.01, max_depth=5, min_child_weight=13, n_estimators=100, n_jobs=1, scale_pos_weight=50, subsample=0.6500000000000001, verbosity=0)),\n",
    "#         ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion=\"gini\", max_features=0.45, min_samples_leaf=19, min_samples_split=14, n_estimators=100)\n",
    "#     )\n",
    "\n",
    "#     clf = make_pipeline(\n",
    "#         VarianceThreshold(threshold=0.1),\n",
    "#         ZeroCount(),\n",
    "#         RFE(LogisticRegression(penalty=\"l1\", solver=\"liblinear\", fit_intercept=True, dual=False, tol=0.001, class_weight=\"balanced\")),\n",
    "#         StackingEstimator(estimator=\n",
    "#             GradientBoostingClassifier(learning_rate=1.0, max_depth=2, max_features=0.7000000000000001, min_samples_leaf=20, min_samples_split=5, n_estimators=100, subsample=0.05)),\n",
    "#             RandomForestClassifier(bootstrap=True, class_weight=None, criterion=\"gini\", max_features=1.0, min_samples_leaf=8, min_samples_split=15, n_estimators=100)\n",
    "# )\n",
    "\n",
    "#     clf = LogisticRegression(penalty=\"l1\", solver=\"liblinear\", fit_intercept=True, dual=False, tol=0.001, class_weight=\"balanced\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "np.random.seed(930525)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "warnings.simplefilter('once')\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plot_utils as pu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "url = requests.get('https://docs.google.com/spreadsheets/d/1KO_wGiEagJ8PMO2BzSDI1IXHYO4RHZMMSWXlT48peiQ/export?format=csv')\n",
    "csv_raw = StringIO(url.text)\n",
    "df_truth = pd.read_csv(csv_raw)\n",
    "\n",
    "inf_tax_file = \"/mnt/btrfs/data/gtdb_95/gtdb_genomes_reps_r95/r95.gtdb.tax\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tax = pd.read_csv(inf_tax_file, names=[\"assembly_accession\", \"tax\"], sep=\"\\t\")\n",
    "\n",
    "df_tax[\"species\"] = [\";\".join(_.split(\";\")[:7]) for _ in df_tax.tax]\n",
    "df_tax[\"genus\"] = [\";\".join(_.split(\";\")[:6]) for _ in df_tax.tax]\n",
    "df_tax[\"family\"] = [\";\".join(_.split(\";\")[:5]) for _ in df_tax.tax]\n",
    "\n",
    "accession_to_genus = dict()\n",
    "for t in df_tax.itertuples():\n",
    "    accession_to_genus[t.assembly_accession] = t.genus.split(\";\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "files = glob(\"/mnt/btrfs/data/type_1/species_mc/b6_capitalist_split_by_sample/*.extra.tree.csv\")\n",
    "\n",
    "dfs = []\n",
    "for file in files:\n",
    "    name = '_'.join(os.path.basename(file).split('.')[:-4])\n",
    "    df = pd.read_csv(file, index_col = 0)\n",
    "    df['dataset'] = name\n",
    "    dfs.append(df)\n",
    "df_type_1_features = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the true species accessions\n",
    "dd = defaultdict(set)\n",
    "\n",
    "dd_genus = defaultdict(set)\n",
    "for group, df in df_truth.groupby('dataset'):\n",
    "    mask_nan = df_truth['database_accession'].astype(str) == 'nan'\n",
    "    \n",
    "    for row in df.loc[mask_nan].itertuples():\n",
    "        # get the genus of the nans\n",
    "        dd_genus[group].add(\"g__\" + row.name.replace(\"_\", \" \").split()[0])\n",
    "        dd_genus[group].add(\"g__\" + row.homotypic_synonym.replace(\"_\", \" \").split()[0])\n",
    "    \n",
    "    dd[group] = set(df.loc[~mask_nan, \"database_accession\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for i, t in df_type_1_features.iterrows():\n",
    "    if t['assembly_accession'] in dd[t['dataset']]:\n",
    "        rows.append(True)\n",
    "    else:\n",
    "        rows.append(False)\n",
    "df_type_1_features[\"truth\"] = rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assembly Sequence Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob(\"/mnt/btrfs/data/type_1/simulation_cv/*.extra.csv\")\n",
    "\n",
    "dfs = []\n",
    "for file in files:\n",
    "    name = '.'.join(os.path.basename(file).split('.')[1:-3])\n",
    "    df = pd.read_csv(file, index_col = 0)\n",
    "    df['dataset'] = name\n",
    "    dfs.append(df)\n",
    "df_assembly_features = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assembly_truth = pd.read_csv(\"../data/simulation.truth.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_assembly_truth = dict()\n",
    "for group, df in df_assembly_truth.groupby(\"basename\"):\n",
    "    d_assembly_truth[group] = set(df[\"closest_assembly_accession\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for i, t in df_assembly_features.iterrows():\n",
    "    if t['assembly_accession'] in d_assembly_truth[t['dataset']]:\n",
    "        rows.append(True)\n",
    "    else:\n",
    "        rows.append(False)\n",
    "df_assembly_features[\"truth\"] = rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assembly_features['relative_abundance'] = df_assembly_features['hits'] / df_assembly_features.groupby('dataset')['hits'].transform('sum')\n",
    "\n",
    "df_assembly_features['dataset_cat'] = \"assembly\"\n",
    "df_assembly_features.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_type_1_features['relative_abundance'] = df_type_1_features['hits'] / df_type_1_features.groupby('dataset')['hits'].transform('sum')\n",
    "\n",
    "df_type_1_features.reset_index(inplace=True, drop=True)\n",
    "df_type_1_features['dataset_cat'] = pd.Series([_.split(\"_\")[0] for _ in df_type_1_features['dataset']], dtype='category')\n",
    "\n",
    "categories = df_type_1_features['dataset_cat'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_test = df_type_1_features['dataset_cat'] == \"zymo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_type_1_features.loc[~filter_test, :].copy().reset_index(drop=True)\n",
    "test = df_type_1_features.loc[filter_test, :].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_in = np.array([_.split(\".\")[1] in [\"0\", \"1\", \"2\"] for _ in df_assembly_features.dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_assembly = df_assembly_features.loc[mask_in, :].copy().reset_index(drop=True)\n",
    "test_assembly = df_assembly_features.loc[~mask_in, :].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.concat([train_assembly, train])\n",
    "# df_test = pd.concat([test_assembly, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([train_assembly, train])\n",
    "df_test = pd.concat([test_assembly, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['dataset_cat'] = df_train[\"dataset_cat\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import PredefinedSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cv = PredefinedSplit(df_train['dataset_cat'].cat.codes)\n",
    "categories = df_train['dataset_cat'].cat.categories\n",
    "\n",
    "X = df_train.loc[:, [\"relative_abundance\"]].copy()\n",
    "X.reset_index(inplace=True, drop=True)\n",
    "y = df_train.loc[:, [\"truth\"]].copy()\n",
    "y.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "precisions = []\n",
    "average_precisions = []\n",
    "mean_recall = np.linspace(0, 1, 100)\n",
    "classifiers = []\n",
    "\n",
    "for i, (train, test) in enumerate(cv.split(X, y)):\n",
    "    clf = LogisticRegression(class_weight=\"balanced\")\n",
    "    clf.fit(X.loc[train], y.loc[train])\n",
    "    classifiers.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for i, ((train, test), classifier) in enumerate(zip(cv.split(X, y), classifiers)):\n",
    "    viz = plot_precision_recall_curve(classifier, X.loc[test], y.loc[test],\n",
    "                     name=f'{categories[i]}',\n",
    "                     alpha=0.3, lw=1, ax=ax)\n",
    "    interp_precision = np.interp(mean_recall, viz.recall[::-1], viz.precision[::-1])\n",
    "    interp_precision[0] = 1.0\n",
    "    precisions.append(interp_precision)\n",
    "    average_precisions.append(viz.average_precision)\n",
    "    y_pred = classifier.predict(X.loc[test])\n",
    "    print(f\"Dataset: {categories[i]}\")\n",
    "    print(f\"F1: {f1_score(y.loc[test], y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(y.loc[test], y_pred)}\")\n",
    "    print(f\"Recall: {recall_score(y.loc[test], y_pred)}\")\n",
    "    print(f\"Num Predicted: {y_pred.sum()}\")\n",
    "    \n",
    "\n",
    "mean_precision = np.mean(precisions, axis=0)\n",
    "mean_precision[-1] = 0.0\n",
    "mean_average_precisions = np.mean(average_precisions)\n",
    "std_average_precisions = np.std(average_precisions)\n",
    "\n",
    "ax.plot(mean_recall, mean_precision, color='b',\n",
    "        label=r'Mean PR (AP = %0.2f $\\pm$ %0.2f)' % (mean_average_precisions, std_average_precisions),\n",
    "        lw=2, alpha=.8)\n",
    "\n",
    "mean_recall_cap = mean_recall.copy()\n",
    "mean_precision_cap = mean_precision.copy()\n",
    "mean_average_precisions_cap = mean_average_precisions.copy()\n",
    "std_average_precisions_cap = std_average_precisions.copy()\n",
    "\n",
    "# calculate the no skill line as the proportion of the positive class\n",
    "# no_skill = len(y[y==False]) / len(y)\n",
    "# # plot the no skill precision-recall curve\n",
    "# plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label=f'No Skill ( AP = {no_skill:.5f})')\n",
    "\n",
    "std_precisions = np.std(precisions, axis=0)\n",
    "precisions_upper = np.minimum(mean_precision + std_precisions, 1)\n",
    "precisions_lower = np.maximum(mean_precision - std_precisions, 0)\n",
    "ax.fill_between(mean_recall, precisions_lower, precisions_upper, color='grey', alpha=.2,\n",
    "                label=r'$\\pm$ 1 std. dev.')\n",
    "precisions_upper_cap = precisions_upper.copy()\n",
    "precisions_lower_cap = precisions_lower.copy()\n",
    "\n",
    "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "       title=\"Precision Recall Curves\")\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for clf in classifiers:\n",
    "    plt.plot(np.arange(0, 1, .001), clf.predict_proba(np.atleast_2d(np.arange(0, 1, .001)).T)[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['hits',\n",
    " 'percent_coverage',\n",
    " 'mean_coverage',\n",
    " 'sd_coverage',\n",
    " 'percent_binned_coverage',\n",
    " 'mean_binned_coverage',\n",
    " 'sd_binned_coverage',\n",
    " 'expected_percent_coverage',\n",
    " 'shannon_entropy',\n",
    " 'percent_max_uncovered_region',\n",
    " 'largest_pileup',\n",
    " 'largest_binned_pileup',\n",
    " 'gc_content',\n",
    " 'total_genome_length',\n",
    " 'ungapped_genome_length',\n",
    " 'num_n_groups',\n",
    " 'consecutive_ns',\n",
    " 'tree_dist',\n",
    " 'tree_top_dist',\n",
    " 'gf_checkm_completeness',\n",
    " 'gf_checkm_contamination',\n",
    " 'relative_abundance',\n",
    " 'tree_hits',\n",
    " 'tree_percent_coverage',\n",
    " 'tree_mean_coverage',\n",
    " 'tree_sd_coverage',\n",
    " 'tree_percent_binned_coverage',\n",
    " 'tree_mean_binned_coverage',\n",
    " 'tree_sd_binned_coverage',\n",
    " 'tree_expected_percent_coverage',\n",
    " 'tree_shannon_entropy',\n",
    " 'tree_percent_max_uncovered_region',\n",
    " 'tree_largest_pileup',\n",
    " 'tree_largest_binned_pileup',\n",
    " 'tree_dist',\n",
    " 'tree_top_dist'\n",
    "]\n",
    "\n",
    "# features = [\n",
    "#  'gf_checkm_completeness',\n",
    "#  'gf_checkm_contamination',\n",
    "#  'tree_relative_abundance'\n",
    "# ]\n",
    "\n",
    "# features = ['relative_abundance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train[features + [\"assembly_accession\", \"dataset\", \"truth\", \"dataset_cat\"]]\n",
    "\n",
    "# X = X.replace([np.inf, -np.inf], np.nan)\n",
    "# X = X.loc[:, features].dropna()\n",
    "\n",
    "cv = PredefinedSplit(X['dataset_cat'].cat.codes)\n",
    "X = X.loc[:, features].copy()\n",
    "X.reset_index(inplace=True, drop=True)\n",
    "\n",
    "y = df_train.loc[:, \"truth\"]\n",
    "y.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions = []\n",
    "average_precisions = []\n",
    "mean_recall = np.linspace(0, 1, 100)\n",
    "classifiers = []\n",
    "\n",
    "# columns = rfecv.ranking_\n",
    "\n",
    "# df_X_transf = pd.DataFrame(X_transf[:, columns == 1], columns = X.columns[columns == 1])\n",
    "\n",
    "# X_transf = rfecv.transform(X)\n",
    "# X_transf = X_transf.copy().values\n",
    "X_transf = X.copy().values\n",
    "# X.reset_index(inplace=True, drop=True)\n",
    "y.reset_index(inplace=True, drop=True)\n",
    "\n",
    "for i, (train, test) in enumerate(cv.split(X_transf, y)):\n",
    "#     clf = RandomForestClassifier(n_estimators=100, max_features=.2, min_samples_leaf=17, min_samples_split=9, bootstrap=False, criterion=\"gini\", class_weight=\"balanced_subsample\")\n",
    "#     clf = ExtraTreesClassifier(bootstrap=True, class_weight=None, criterion='entropy', max_features=0.8, min_samples_leaf=4, min_samples_split=20, n_estimators=100)\n",
    "    clf = make_pipeline(*pipe)\n",
    "#     clf = make_pipeline(\n",
    "# #         MinMaxScaler(),\n",
    "# #         RFE(LogisticRegression(penalty=\"l1\", solver=\"liblinear\", fit_intercept=True, dual=False, tol=0.001, class_weight=\"balanced\")),\n",
    "#         StackingEstimator(estimator=XGBClassifier(learning_rate=0.01, max_depth=5, min_child_weight=13, n_estimators=100, n_jobs=1, scale_pos_weight=50, subsample=0.6500000000000001, verbosity=0)),\n",
    "#         ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion=\"gini\", max_features=0.45, min_samples_leaf=19, min_samples_split=14, n_estimators=100)\n",
    "#     )\n",
    "\n",
    "#     clf = make_pipeline(\n",
    "#         VarianceThreshold(threshold=0.1),\n",
    "#         ZeroCount(),\n",
    "#         RFE(LogisticRegression(penalty=\"l1\", solver=\"liblinear\", fit_intercept=True, dual=False, tol=0.001, class_weight=\"balanced\")),\n",
    "#         StackingEstimator(estimator=\n",
    "#             GradientBoostingClassifier(learning_rate=1.0, max_depth=2, max_features=0.7000000000000001, min_samples_leaf=20, min_samples_split=5, n_estimators=100, subsample=0.05)),\n",
    "#             RandomForestClassifier(bootstrap=True, class_weight=None, criterion=\"gini\", max_features=1.0, min_samples_leaf=8, min_samples_split=15, n_estimators=100)\n",
    "# )\n",
    "\n",
    "#     clf = LogisticRegression(penalty=\"l1\", solver=\"liblinear\", fit_intercept=True, dual=False, tol=0.001, class_weight=\"balanced\")\n",
    "    clf.fit(X_transf[train], y.loc[train])\n",
    "    classifiers.append(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save classifier from entire pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "clf = make_pipeline(*pipe)\n",
    "clf.fit(X_transf[train], y.loc[train])\n",
    "\n",
    "joblib.dump(clf, f'../data/clf.sklearn.all.{clf_name}.pkl', compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "for i, classifier in enumerate(classifiers):\n",
    "    joblib.dump(classifier, f'../data/clf.sklearn.{categories[i]}.{clf_name}.pkl', compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(context=\"paper\", style=\"ticks\", palette=\"colorblind\", font='serif', font_scale=1.5, color_codes=True, rc=pu.figure_setup())\n",
    "\n",
    "ax.yaxis.grid(True)\n",
    "ax.xaxis.grid(False)\n",
    "fig_size = pu.get_fig_size(15, 10)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=fig_size)\n",
    "\n",
    "for i, ((train, test), classifier) in enumerate(zip(cv.split(X_transf, y), classifiers)):\n",
    "    viz = plot_precision_recall_curve(classifier, X_transf[test], y.loc[test],\n",
    "                     name=f'{categories[i]}',\n",
    "                     alpha=0.3, lw=1, ax=ax)\n",
    "    interp_precision = np.interp(mean_recall, viz.recall[::-1], viz.precision[::-1])\n",
    "    interp_precision[0] = 1.0\n",
    "    precisions.append(interp_precision)\n",
    "    average_precisions.append(viz.average_precision)\n",
    "    y_pred = classifier.predict(X_transf[test])\n",
    "    print(f\"Dataset: {categories[i]}\")\n",
    "    print(f\"F1: {f1_score(y.loc[test], y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(y.loc[test], y_pred)}\")\n",
    "    print(f\"Recall: {recall_score(y.loc[test], y_pred)}\")\n",
    "    print(f\"Num Predicted: {y_pred.sum()}\")\n",
    "    \n",
    "\n",
    "mean_precision = np.mean(precisions, axis=0)\n",
    "mean_precision[-1] = 0.0\n",
    "mean_average_precisions = np.mean(average_precisions)\n",
    "std_average_precisions = np.std(average_precisions)\n",
    "\n",
    "ax.plot(mean_recall, mean_precision, color='b',\n",
    "        label=r'Mean PR (AP = %0.2f $\\pm$ %0.2f)' % (mean_average_precisions, std_average_precisions),\n",
    "        lw=2, alpha=.8)\n",
    "\n",
    "ax.plot(mean_recall_cap, mean_precision_cap, color='r',\n",
    "        label=r'Baseline Mean PR (AP = %0.2f $\\pm$ %0.2f)' % (mean_average_precisions_cap, std_average_precisions_cap),\n",
    "        lw=2, alpha=.8)\n",
    "\n",
    "# calculate the no skill line as the proportion of the positive class\n",
    "# no_skill = len(y[y==False]) / len(y)\n",
    "# # plot the no skill precision-recall curve\n",
    "# plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label=f'No Skill ( AP = {no_skill:.5f})')\n",
    "\n",
    "std_precisions = np.std(precisions, axis=0)\n",
    "precisions_upper = np.minimum(mean_precision + std_precisions, 1)\n",
    "precisions_lower = np.maximum(mean_precision - std_precisions, 0)\n",
    "ax.fill_between(mean_recall, precisions_lower, precisions_upper, color='grey', alpha=.2,\n",
    "                label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "ax.fill_between(mean_recall_cap, precisions_lower_cap, precisions_upper_cap, color='grey', alpha=.2,\n",
    "                label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "       title=\"Precision Recall Curves\")\n",
    "\n",
    "\n",
    "pu.stylize_axes(ax)\n",
    "pu.stylize_fig(fig)\n",
    "plt.tight_layout()\n",
    "\n",
    "artists = ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "artists.set_frame_on(False)\n",
    "\n",
    "pu.save_plot(fig, f\"pr_curves.train.{clf_name}\", artists=(artists,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=fig_size)\n",
    "\n",
    "classifier = clf.fit(X_transf, y)\n",
    "\n",
    "X_test = df_test[features + [\"assembly_accession\", \"dataset\", \"truth\", \"dataset_cat\"]]\n",
    "X_test = X_test.loc[:, features].copy()\n",
    "X_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "y_test = df_test.loc[:, \"truth\"]\n",
    "y_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "viz = plot_precision_recall_curve(classifier, X_test, y_test, alpha=0.3, lw=1, ax=ax, name=clf_name)\n",
    "interp_precision = np.interp(mean_recall, viz.recall[::-1], viz.precision[::-1])\n",
    "interp_precision[0] = 1.0\n",
    "precisions.append(interp_precision)\n",
    "average_precisions.append(viz.average_precision)\n",
    "y_pred = classifier.predict(X_transf[test])\n",
    "# print(f\"Dataset: {categories[i]}\")\n",
    "print(f\"F1: {f1_score(y.loc[test], y_pred)}\")\n",
    "print(f\"Precision: {precision_score(y.loc[test], y_pred)}\")\n",
    "print(f\"Recall: {recall_score(y.loc[test], y_pred)}\")\n",
    "print(f\"Num Predicted: {y_pred.sum()}\")\n",
    "\n",
    "classifier = logistic.fit(X_transf, y)\n",
    "\n",
    "viz = plot_precision_recall_curve(classifier, X_test, y_test, alpha=0.3, lw=1, ax=ax, name=\"Logistic Regression\")\n",
    "interp_precision = np.interp(mean_recall, viz.recall[::-1], viz.precision[::-1])\n",
    "interp_precision[0] = 1.0\n",
    "precisions.append(interp_precision)\n",
    "average_precisions.append(viz.average_precision)\n",
    "y_pred = classifier.predict(X_transf[test])\n",
    "# print(f\"Dataset: {categories[i]}\")\n",
    "print(f\"F1: {f1_score(y.loc[test], y_pred)}\")\n",
    "print(f\"Precision: {precision_score(y.loc[test], y_pred)}\")\n",
    "print(f\"Recall: {recall_score(y.loc[test], y_pred)}\")\n",
    "print(f\"Num Predicted: {y_pred.sum()}\")\n",
    "pu.save_plot(fig, f\"pr_curve.test.{clf_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-type_1]",
   "language": "python",
   "name": "conda-env-.conda-type_1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
